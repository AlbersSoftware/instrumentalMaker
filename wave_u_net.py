# -*- coding: utf-8 -*-
"""Wave-U-net.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aA6BpQ9MhqnALnMjunojAi1Jd5_5rVex
"""

import tensorflow as tf
import numpy as np
from tensorflow.keras.layers import Layer

class AudioClipLayer(Layer):

    def __init__(self, units=32, **kwargs):
        '''Initializes the instance attributes'''
        super(AudioClipLayer, self).__init__(**kwargs)
        self.units = units

    def build(self, input_shape):
        '''Create the state of the layer (weights)'''
        # initialize the weights
        pass
        
    def call(self, inputs, training):
        '''Defines the computation from inputs to outputs'''
        if training:
            return inputs
        else:
            return tf.maximum(tf.minimum(inputs, 1.0), -1.0)

#        return tf.matmul(inputs, self.w) + self.b

# Learned Interpolation layer

class InterpolationLayer(Layer):

    def __init__(self, units=32, **kwargs):
        '''Initializes the instance attributes'''
        super(InterpolationLayer, self).__init__(**kwargs)
        self.units = units

    def build(self, input_shape):
        '''Create the state of the layer (weights)'''
        self.features = input_shape.as_list()[3]

        # initialize the weights
        w_init = tf.random_normal_initializer()
        self.w = tf.Variable(name="kernel",
            initial_value=w_init(shape=(self.features, ),
                                 dtype='float32'),
            trainable=True)

    def call(self, inputs):
        '''Defines the computation from inputs to outputs'''

        w_scaled = tf.math.sigmoid(self.w)

        counter_w = 1 - w_scaled

        conv_weights = tf.expand_dims(tf.concat([tf.expand_dims(tf.linalg.diag(w_scaled), axis=0), tf.expand_dims(tf.linalg.diag(counter_w), axis=0)], axis=0), axis=0)

        intermediate_vals = tf.nn.conv2d(inputs, conv_weights, strides=[1,1,1,1], padding="VALID")

        intermediate_vals = tf.transpose(intermediate_vals, [2, 0, 1, 3])
        out = tf.transpose(inputs, [2, 0, 1, 3])
        
        num_entries = out.shape.as_list()[0]
        out = tf.concat([out, intermediate_vals], axis=0)

        indices = list()

        num_outputs = 2*num_entries - 1

        for idx in range(num_outputs):
            if idx % 2 == 0:
                indices.append(idx // 2)
            else:
                indices.append(num_entries + idx//2)
        out = tf.gather(out, indices)
        current_layer = tf.transpose(out, [1, 2, 0, 3])

        return current_layer

class CropLayer(Layer):
    def __init__(self, x2, match_feature_dim=True, **kwargs):
        '''Initializes the instance attributes'''
        super(CropLayer, self).__init__(**kwargs)
        self.match_feature_dim = match_feature_dim
        self.x2 = x2

    def build(self, input_shape):
        '''Create the state of the layer (weights)'''
        # initialize the weights
        pass
        
    def call(self, inputs):
        '''Defines the computation from inputs to outputs'''
        if self.x2 is None:
            return inputs

        inputs = self.crop(inputs, self.x2.shape.as_list(), self.match_feature_dim)
        return inputs

    def crop(self, tensor, target_shape, match_feature_dim=True):
        '''
        Crops a 3D tensor [batch_size, width, channels] along the width axes to a target shape.
        Performs a centre crop. If the dimension difference is uneven, crop last dimensions first.
        :param tensor: 4D tensor [batch_size, width, height, channels] that should be cropped. 
        :param target_shape: Target shape (4D tensor) that the tensor should be cropped to
        :return: Cropped tensor
        '''
        shape = np.array(tensor.shape.as_list())

        ddif = shape[1] - target_shape[1]

        if (ddif % 2 != 0):
            print("WARNING: Cropping with uneven number of extra entries on one side")
        # assert diff[1] >= 0 # Only positive difference allowed
        if ddif == 0:
            return tensor
        crop_start = ddif // 2
        crop_end = ddif - crop_start

        return tensor[:,crop_start:-crop_end,:]

class DiffOutputLayer(Layer):

    def __init__(self, source_names, num_channels, filter_width, **kwargs):
        '''Initializes the instance attributes'''
        super(DiffOutputLayer, self).__init__(**kwargs)
        self.source_names = source_names
        self.num_channels = num_channels
        self.filter_width = filter_width

        self.conv1a = tf.keras.layers.Conv1D(self.num_channels, self.filter_width, padding='valid')


    def build(self, input_shape):
        '''Create the state of the layer (weights)'''
        pass
        
    def call(self, inputs, training):
        '''Defines the computation from inputs to outputs'''
        outputs = {}
        outsss = []
        sum_source = 0
        for name in self.source_names[:-1]:
            out = self.conv1a(inputs[0])
            out = AudioClipLayer()(out)
            outputs[name] = out
            outsss.append(out)
            sum_source = sum_source + out
        
        
        last_source = CropLayer(sum_source)(inputs[1]) - sum_source
        last_source = AudioClipLayer()(last_source)

        outputs[self.source_names[-1]] = last_source

        return outputs

def wave_u_net():
  num_initial_filters = 24
  num_layers = 12
  kernel_size = 15
  merge_filter_size = 5
  source_names = ["bass", "drums", "other", "vocals"]
  num_channels = 1
  output_filter_size = 1

  # `enc_outputs` stores the downsampled outputs to re-use during upsampling.
  enc_outputs = []

  # `raw_input` is the input to the network
  raw_input = tf.keras.layers.Input(shape=(147443, 1),name="raw_input")
  X = raw_input
  inp = raw_input

  # Down sampling
  for i in range(num_layers):
    X = tf.keras.layers.Conv1D(filters=num_initial_filters + (num_initial_filters * i),
                          kernel_size=kernel_size,strides=1,
                          padding='valid', name="Down_Conv_"+str(i))(X)
    X = tf.keras.layers.LeakyReLU(name="DC_Act_"+str(i))(X)

    enc_outputs.append(X)

    X = tf.keras.layers.Lambda(lambda x: x[:,::2,:], name="Decimate_"+str(i))(X)


  X = tf.keras.layers.Conv1D(filters=num_initial_filters + (num_initial_filters * num_layers),
                          kernel_size=kernel_size,strides=1,
                          padding='valid', name="Down_Conv_"+str(num_layers))(X)
  X = tf.keras.layers.LeakyReLU(name="DC_Act_"+str(num_layers))(X)



  # Up sampling
  for i in range(num_layers):
    X = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=1), name="exp_dims_"+str(i))(X)

    X = InterpolationLayer(name="IntPol_"+str(i))(X)

    X = tf.keras.layers.Lambda(lambda x: tf.squeeze(x, axis=1), name="sq_dims_"+str(i))(X)
    
    c_layer = CropLayer(X, False, name="crop_layer_"+str(i))(enc_outputs[-i-1])
    X = tf.keras.layers.Concatenate(axis=2, name="concatenate_"+str(i))([X, c_layer]) 


    X = tf.keras.layers.Conv1D(filters=num_initial_filters + (num_initial_filters * (num_layers - i - 1)),
                            kernel_size=merge_filter_size,strides=1,
                            padding='valid', name="Up_Conv_"+str(i))(X)
    X = tf.keras.layers.LeakyReLU(name="UC_Act_"+str(i))(X)


  c_layer = CropLayer(X, False, name="crop_layer_"+str(num_layers))(inp)
  X = tf.keras.layers.Concatenate(axis=2, name="concatenate_"+str(num_layers))([X, c_layer]) 
  X = AudioClipLayer(name="audio_clip_"+str(0))(X)


  # Difference Output
  cropped_input = CropLayer(X, False, name="crop_layer_"+str(num_layers+1))(inp)
  X = DiffOutputLayer(source_names, num_channels, output_filter_size, name="diff_out")([X, cropped_input])

  o = X
  model = tf.keras.Model(inputs=raw_input, outputs=o)
  return model
